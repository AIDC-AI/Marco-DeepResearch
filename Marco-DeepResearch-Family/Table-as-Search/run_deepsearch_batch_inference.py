#!/usr/bin/env python3
# Copyright (C) 2026 AIDC-AI
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
æ‰¹é‡æ¨ç†è¿è¡Œè„šæœ¬ - æ”¯æŒå¹¶è¡Œè¿è¡Œå¤šä¸ª deepsearch ä»»åŠ¡
å¤ç”¨ run_deepsearch_inference.py çš„ run_inference å‡½æ•°

æ³¨æ„ï¼šä½¿ç”¨ multiprocessing è€Œé threading æ¥å®ç°çœŸæ­£çš„è¶…æ—¶æ§åˆ¶
å› ä¸º Python çš„çº¿ç¨‹æ— æ³•è¢«å¼ºåˆ¶ç»ˆæ­¢ï¼Œåªæœ‰è¿›ç¨‹å¯ä»¥è¢« terminate/kill
"""

# ============================================================================
# âš ï¸ CRITICAL: Load environment variables FIRST, before any other imports!
# ============================================================================
from tools.env_loader import load_dotenv
load_dotenv(override=True)

import argparse
import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict
import traceback
import multiprocessing
from multiprocessing import Process, Queue

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
BASE_DIR = Path(__file__).parent.absolute()
sys.path.insert(0, str(BASE_DIR))

# å¯¼å…¥ run_inference å‡½æ•°å’Œ clear_database_tables å‡½æ•°
from run_deepsearch_inference import run_inference, clear_database_tables
from rich.console import Console
from tools.dataloader import *

console = Console()


def _run_single_task_in_process(
    example: Dict,
    main_model_id: str,
    tabular_model_id: str,
    deep_model_id: str,
    output_dir: str,
    db_name: str,
    clear_db: bool,
    use_summary_tool: bool,
    tool_response_retention_budget: Optional[int],
    max_tool_threads: Optional[int],
    use_out_key: bool,
    global_visit_limit: Optional[int],
    global_search_limit: Optional[int],
    main_max_steps: int,
    subagent_max_steps: int,
    main_enable_context_summarization: bool,
    main_context_token_threshold: int,
    tabular_enable_context_summarization: bool,
    tabular_context_token_threshold: int,
    deep_enable_context_summarization: bool,
    deep_context_token_threshold: int,
    tabular_agent_limit: Optional[int],
    deep_agent_limit: Optional[int],
    result_queue: Queue
):
    """
    åœ¨å­è¿›ç¨‹ä¸­è¿è¡Œå•ä¸ªä»»åŠ¡çš„å‡½æ•°
    
    è¿™ä¸ªå‡½æ•°ä¼šåœ¨ç‹¬ç«‹çš„è¿›ç¨‹ä¸­æ‰§è¡Œï¼Œå¯ä»¥è¢«ä¸»è¿›ç¨‹å¼ºåˆ¶ç»ˆæ­¢
    ç»“æœé€šè¿‡ Queue ä¼ é€’å›ä¸»è¿›ç¨‹
    """
    # åœ¨å­è¿›ç¨‹ä¸­é‡æ–°åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv(override=True)
    
    instance_id = example["instance_id"]
    task_id = example.get("task_id", instance_id)
    query = example["question"]
    true_answer = example.get('true_answer', '')
    annotator_metadata = example.get('Annotator_Metadata', {})
    
    start_time = datetime.now()
    output = None
    error = None
    run_inference_result = None
    
    process_id = os.getpid()
    print(f"[{instance_id}] ğŸš€ Starting task in process {process_id} at {start_time.strftime('%H:%M:%S')}")
    
    try:
        output_path = Path(output_dir)
        
        # è°ƒç”¨ run_inference
        output = run_inference(
            question=query,
            true_answer=true_answer,
            annotator_metadata=annotator_metadata,
            main_model_id=main_model_id,
            tabular_model_id=tabular_model_id,
            deep_model_id=deep_model_id,
            output_dir=str(output_path),
            db_name=db_name,
            clear_db=clear_db,
            use_summary_tool=use_summary_tool,
            instance_id=instance_id,
            tool_response_retention_budget=tool_response_retention_budget,
            max_tool_threads=max_tool_threads,
            use_out_key=use_out_key,
            global_visit_limit=global_visit_limit,
            global_search_limit=global_search_limit,
            main_max_steps=main_max_steps,
            subagent_max_steps=subagent_max_steps,
            main_enable_context_summarization=main_enable_context_summarization,
            main_context_token_threshold=main_context_token_threshold,
            tabular_enable_context_summarization=tabular_enable_context_summarization,
            tabular_context_token_threshold=tabular_context_token_threshold,
            deep_enable_context_summarization=deep_enable_context_summarization,
            deep_context_token_threshold=deep_context_token_threshold,
            tabular_agent_limit=tabular_agent_limit,
            deep_agent_limit=deep_agent_limit
        )
        
        # è¯»å– run_inference ä¿å­˜çš„ç»“æœæ–‡ä»¶
        result_file = output_path / f"{instance_id}.json"
        if result_file.exists():
            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    run_inference_result = json.load(f)
            except:
                run_inference_result = None
                
    except Exception as e:
        error = str(e)
        print(f"[{instance_id}] âŒ ERROR: {type(e).__name__}: {error}")
        traceback.print_exc()
    
    # æ„å»ºç»“æœ
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    if run_inference_result:
        result = run_inference_result.copy()
        result["query"] = query
        result["error"] = error
        result["timeout"] = False
    else:
        result = {
            "instance_id": instance_id,
            "task_id": task_id,
            "query": query,
            "question": query,
            "answer": str(output) if output else None,
            "response": str(output) if output else None,
            "error": error,
            "timeout": False,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration,
            "main_model_id": main_model_id,
            "tabular_model_id": tabular_model_id,
            "deep_model_id": deep_model_id,
        }
    
    # å°†ç»“æœæ”¾å…¥é˜Ÿåˆ—
    result_queue.put(result)


def contains_tool_tags(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«å·¥å…·æ ‡ç­¾ï¼Œè¯´æ˜ä»»åŠ¡è¢«ä¸­æ–­æœªæ­£å¸¸å®Œæˆ"""
    if not text:
        return False
    
    text_str = str(text)
    
    # æ£€æµ‹å¸¸è§çš„å·¥å…·è°ƒç”¨æ ‡ç­¾æ¨¡å¼
    tool_patterns = [
        r'```json',       # ```json (ä»£ç å—å¼€å§‹)
        #r'```python',     # ```python (ä»£ç å—å¼€å§‹)
        r'```\s*\{',      # ``` { ... } (é€šç”¨ä»£ç å—)
        r'Action:\s*',    # Action: ...
        r'Thought:\s*',   # Thought: ...
        r'"name":\s*"[^"]*"',  # JSON ä¸­çš„å·¥å…·åç§°
        r"'name':\s*'[^']*'",  # JSON ä¸­çš„å·¥å…·åç§°
        r"'arguments':\s*\{",  # JSON ä¸­çš„å·¥å…·å‚æ•°
        r'"arguments":\s*\{',  # JSON ä¸­çš„å·¥å…·å‚æ•°
        r'Calling tools' # tool-calling keywords
    ]
    
    for pattern in tool_patterns:
        if re.search(pattern, text_str, re.IGNORECASE | re.MULTILINE):
            return True
    
    return False


def is_task_completed(instance_id: str, output_dir: Path) -> bool:
    """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»å®Œæˆ - é€šè¿‡æ£€æŸ¥ {instance_id}.json æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    result_file = output_dir / f"{instance_id}.json"
    if result_file.exists():
        # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯é”™è¯¯ï¼‰
        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                result = json.load(f)
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ç­”æ¡ˆï¼ˆä¸æ˜¯é”™è¯¯ï¼‰
                answer = result.get("answer") or result.get("response")
                if answer:
                    # æ£€æŸ¥æ˜¯å¦ä»¥ Error: å¼€å¤´
                    if str(answer).startswith("Error:"):
                        return False
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·æ ‡ç­¾ï¼ˆè¯´æ˜ä»»åŠ¡è¢«ä¸­æ–­ï¼‰
                    if contains_tool_tags(answer):
                        console.print(f"[yellow]âš ï¸  Task {instance_id} contains tool tags, marking as incomplete[/yellow]")
                        return False
                    return True
        except:
            # å¦‚æœæ–‡ä»¶æŸåï¼Œè®¤ä¸ºæœªå®Œæˆ
            return False
    return False


def run_single_task_with_timeout(
    example: Dict,
    main_model_id: str,
    tabular_model_id: str,
    deep_model_id: str,
    output_dir: Path,
    db_name: str,
    clear_db: bool,
    use_summary_tool: bool,
    tool_response_retention_budget: Optional[int] = None,
    max_tool_threads: Optional[int] = None,
    use_out_key: bool = False,
    global_visit_limit: Optional[int] = None,
    global_search_limit: Optional[int] = None,
    main_max_steps: int = 40,
    subagent_max_steps: int = 40,
    main_enable_context_summarization: bool = False,
    main_context_token_threshold: int = 80000,
    tabular_enable_context_summarization: bool = False,
    tabular_context_token_threshold: int = 60000,
    deep_enable_context_summarization: bool = False,
    deep_context_token_threshold: int = 60000,
    tabular_agent_limit: Optional[int] = None,
    deep_agent_limit: Optional[int] = None,
    timeout_seconds: int = 3600
) -> Dict:
    """è¿è¡Œå•ä¸ªä»»åŠ¡ï¼Œå¸¦çœŸæ­£çš„è¶…æ—¶æ§åˆ¶ï¼ˆä½¿ç”¨ multiprocessingï¼‰
    
    å…³é”®ï¼šä½¿ç”¨ multiprocessing.Process è€Œé threading
    å› ä¸º Python çº¿ç¨‹æ— æ³•è¢«å¼ºåˆ¶ç»ˆæ­¢ï¼Œä½†è¿›ç¨‹å¯ä»¥é€šè¿‡ terminate() æˆ– kill() ç»ˆæ­¢
    """
    instance_id = example["instance_id"]
    task_id = example.get("task_id", instance_id)
    query = example["question"]
    
    start_time = datetime.now()
    
    console.print(f"[cyan][{instance_id}] ğŸš€ Starting task in subprocess at {start_time.strftime('%H:%M:%S')} (timeout: {timeout_seconds}s)[/cyan]")
    
    # åˆ›å»ºç”¨äºè¿›ç¨‹é—´é€šä¿¡çš„é˜Ÿåˆ—
    result_queue = multiprocessing.Queue()
    
    # åˆ›å»ºå­è¿›ç¨‹
    process = Process(
        target=_run_single_task_in_process,
        args=(
            example,
            main_model_id,
            tabular_model_id,
            deep_model_id,
            str(output_dir),
            db_name,
            clear_db,
            use_summary_tool,
            tool_response_retention_budget,
            max_tool_threads,
            use_out_key,
            global_visit_limit,
            global_search_limit,
            main_max_steps,
            subagent_max_steps,
            main_enable_context_summarization,
            main_context_token_threshold,
            tabular_enable_context_summarization,
            tabular_context_token_threshold,
            deep_enable_context_summarization,
            deep_context_token_threshold,
            tabular_agent_limit,
            deep_agent_limit,
            result_queue
        )
    )
    
    # å¯åŠ¨å­è¿›ç¨‹
    process.start()
    
    # ç­‰å¾…å­è¿›ç¨‹å®Œæˆï¼Œå¸¦è¶…æ—¶
    process.join(timeout=timeout_seconds)
    
    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œï¼ˆå³è¶…æ—¶äº†ï¼‰
    if process.is_alive():
        console.print(f"[bold red][{instance_id}] â° TIMEOUT after {timeout_seconds}s - Terminating process...[/bold red]")
        
        # å…ˆå°è¯•ä¼˜é›…ç»ˆæ­¢
        process.terminate()
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©è¿›ç¨‹æ¸…ç†
        process.join(timeout=10)
        
        # å¦‚æœè¿˜åœ¨è¿è¡Œï¼Œå¼ºåˆ¶æ€æ­»
        if process.is_alive():
            console.print(f"[bold red][{instance_id}] Process did not terminate, forcing kill...[/bold red]")
            process.kill()
            process.join(timeout=5)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # è¿”å›è¶…æ—¶ç»“æœ
        return {
            "instance_id": instance_id,
            "task_id": task_id,
            "query": query,
            "question": query,
            "answer": None,
            "response": None,
            "error": f"Task timeout after {timeout_seconds} seconds (actual duration: {duration:.1f}s)",
            "timeout": True,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration,
            "main_model_id": main_model_id,
            "tabular_model_id": tabular_model_id,
            "deep_model_id": deep_model_id,
        }
    
    # è¿›ç¨‹æ­£å¸¸å®Œæˆï¼Œä»é˜Ÿåˆ—è·å–ç»“æœ
    try:
        # ä½¿ç”¨éé˜»å¡æ–¹å¼è·å–ç»“æœï¼Œä»¥é˜²é˜Ÿåˆ—ä¸ºç©º
        if not result_queue.empty():
            result = result_queue.get(timeout=5)
            console.print(f"[bold green][{instance_id}] âœ… Task completed successfully[/bold green]")
            return result
        else:
            # é˜Ÿåˆ—ä¸ºç©ºï¼Œå¯èƒ½æ˜¯è¿›ç¨‹å¼‚å¸¸é€€å‡º
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            console.print(f"[bold yellow][{instance_id}] âš ï¸ Process completed but no result in queue[/bold yellow]")
            
            # å°è¯•è¯»å–ç»“æœæ–‡ä»¶
            result_file = output_dir / f"{instance_id}.json"
            if result_file.exists():
                try:
                    with open(result_file, 'r', encoding='utf-8') as f:
                        result = json.load(f)
                    result["query"] = query
                    result["timeout"] = False
                    return result
                except:
                    pass
            
            return {
                "instance_id": instance_id,
                "task_id": task_id,
                "query": query,
                "question": query,
                "answer": None,
                "response": None,
                "error": "Process completed but returned no result",
                "timeout": False,
                "start_time": start_time.isoformat(),
                "end_time": end_time.isoformat(),
                "duration_seconds": duration,
                "main_model_id": main_model_id,
                "tabular_model_id": tabular_model_id,
                "deep_model_id": deep_model_id,
            }
    except Exception as e:
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        console.print(f"[bold red][{instance_id}] âŒ Error getting result from queue: {e}[/bold red]")
        return {
            "instance_id": instance_id,
            "task_id": task_id,
            "query": query,
            "question": query,
            "answer": None,
            "response": None,
            "error": f"Error getting result: {str(e)}",
            "timeout": False,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "duration_seconds": duration,
            "main_model_id": main_model_id,
            "tabular_model_id": tabular_model_id,
            "deep_model_id": deep_model_id,
        }


def run_deepsearch_batch(
    input_file: str,
    main_model_id: str,
    tabular_model_id: str,
    deep_model_id: str,
    output_dir: str,
    db_name: str,
    clear_db: bool,
    use_summary_tool: bool,
    max_workers: int = 4,
    start_idx: int = 0,
    end_idx: Optional[int] = None,
    skip_completed: bool = True,
    timeout_seconds: int = 3600,
    tool_response_retention_budget: Optional[int] = None,
    max_tool_threads: Optional[int] = None,
    use_out_key: bool = False,
    global_visit_limit: Optional[int] = None,
    global_search_limit: Optional[int] = None,
    main_max_steps: int = 40,
    subagent_max_steps: int = 40,
    main_enable_context_summarization: bool = False,
    main_context_token_threshold: int = 80000,
    tabular_enable_context_summarization: bool = False,
    tabular_context_token_threshold: int = 60000,
    deep_enable_context_summarization: bool = False,
    deep_context_token_threshold: int = 60000,
    tabular_agent_limit: Optional[int] = None,
    deep_agent_limit: Optional[int] = None
):
    """è¿è¡Œ deepsearch æ‰¹é‡æ¨ç†
    
    ä½¿ç”¨ multiprocessing å®ç°çœŸæ­£çš„è¶…æ—¶æ§åˆ¶ï¼š
    - æ¯ä¸ªä»»åŠ¡åœ¨ç‹¬ç«‹çš„å­è¿›ç¨‹ä¸­è¿è¡Œ
    - è¶…æ—¶åå¯ä»¥å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹
    - ä½¿ç”¨çº¿ç¨‹æ± æ¥è°ƒåº¦å¤šä¸ªè¿›ç¨‹ï¼Œå®ç°å¹¶è¡Œæ‰§è¡Œ
    """
    console.print(f"\n[bold cyan]{'='*80}[/bold cyan]")
    console.print(f"[bold cyan]ğŸš€ Starting deepsearch batch inference (with multiprocessing timeout)[/bold cyan]")
    console.print(f"[bold cyan]Input file: {input_file}[/bold cyan]")
    console.print(f"[bold cyan]Timeout per task: {timeout_seconds}s[/bold cyan]")
    console.print(f"[bold cyan]{'='*80}[/bold cyan]\n")
    
    # åŠ è½½æ•°æ®é›†
    if "gaia" in input_file:
        examples = load_gaia_dataset(input_file)
    elif "browsecomp-en" in input_file:
        examples = load_browsecomp_en_dataset(input_file)
    elif "browsecomp-zh" in input_file:
        examples = load_browsecomp_zh_dataset(input_file)
    elif "hle" in input_file.lower():
        examples = load_hle_dataset(input_file)
    else:
        console.print(f"[bold red]âŒ Unknown benchmark: {input_file}[/bold red]")
        return
    
    if not examples:
        console.print(f"[bold red]âŒ No examples loaded from {input_file}[/bold red]")
        return
    
    # åˆ‡ç‰‡å¤„ç†
    if end_idx is None:
        end_idx = len(examples)
    examples = examples[start_idx:end_idx]
    
    console.print(f"[bold]Loaded {len(examples)} examples[/bold]")
    
    # åˆ›å»ºå·¥ä½œç›®å½•
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # è·³è¿‡å·²å®Œæˆçš„ä»»åŠ¡
    if skip_completed:
        original_count = len(examples)
        examples = [ex for ex in examples if not is_task_completed(ex["instance_id"], output_path)]
        skipped_count = original_count - len(examples)
        if skipped_count > 0:
            console.print(f"[yellow]â­ï¸  Skipped {skipped_count} already completed tasks[/yellow]")
        console.print(f"[bold]Remaining tasks: {len(examples)}[/bold]")
    
    if not examples:
        console.print(f"[bold green]âœ… All tasks are already completed![/bold green]")
        return
    
    # å¦‚æœ clear_db=Trueï¼Œåœ¨æ‰¹é‡æ‰§è¡Œå¼€å§‹å‰åªæ¸…ç©ºä¸€æ¬¡æ•°æ®åº“
    if clear_db:
        console.print(f"[bold yellow]ğŸ§¹ Clearing database '{db_name}' before batch execution...[/bold yellow]")
        clear_database_tables(db_name)
        console.print(f"[bold green]âœ“ Database cleared. All tasks will use clear_db=False[/bold green]\n")
    
    # å¤„ç†ä»»åŠ¡
    results = []
    task_clear_db = False  # æ‰¹é‡æ‰§è¡Œæ—¶ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½ä¸å†æ¸…ç©ºæ•°æ®åº“ï¼ˆå·²åœ¨å¼€å§‹å‰æ¸…ç©ºï¼‰
    
    console.print(f"[bold cyan]ğŸ”§ Using {max_workers} parallel workers[/bold cyan]")
    console.print(f"[bold cyan]ğŸ’¡ Each task runs in a separate process with enforced timeout[/bold cyan]\n")
    
    # ä½¿ç”¨çº¿ç¨‹æ± æ¥å¹¶è¡Œè°ƒåº¦å¤šä¸ªä»»åŠ¡ï¼ˆæ¯ä¸ªä»»åŠ¡åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­æ‰§è¡Œï¼‰
    # è¿™é‡Œçº¿ç¨‹åªè´Ÿè´£å¯åŠ¨å’Œç›‘æ§è¿›ç¨‹ï¼ŒçœŸæ­£çš„ä»»åŠ¡æ‰§è¡Œåœ¨å­è¿›ç¨‹ä¸­
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {
            executor.submit(
                run_single_task_with_timeout,
                example,
                main_model_id,
                tabular_model_id,
                deep_model_id,
                output_path,
                db_name,
                task_clear_db,
                use_summary_tool,
                tool_response_retention_budget,
                max_tool_threads,
                use_out_key,
                global_visit_limit,
                global_search_limit,
                main_max_steps,
                subagent_max_steps,
                main_enable_context_summarization,
                main_context_token_threshold,
                tabular_enable_context_summarization,
                tabular_context_token_threshold,
                deep_enable_context_summarization,
                deep_context_token_threshold,
                tabular_agent_limit,
                deep_agent_limit,
                timeout_seconds  # ä¼ é€’è¶…æ—¶å‚æ•°
            ): example for example in examples
        }
        
        console.print(f"[bold green]âœ… Submitted {len(futures)} tasks[/bold green]\n")
        
        # ä½¿ç”¨ rich Progress æ›¿ä»£ tqdm
        from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[bold blue]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console
        ) as progress:
            task = progress.add_task("Processing deepsearch tasks", total=len(examples))
            
            for future in as_completed(futures):
                example = futures[future]
                try:
                    # è¿™é‡Œä¸éœ€è¦å†è®¾ç½® timeoutï¼Œå› ä¸º run_single_task_with_timeout
                    # å†…éƒ¨ä½¿ç”¨ multiprocessing å·²ç»å®ç°äº†çœŸæ­£çš„è¶…æ—¶æ§åˆ¶
                    # ä½†æˆ‘ä»¬åŠ ä¸€ä¸ªé¢å¤–çš„ç¼“å†²æ—¶é—´ä»¥é˜²ä¸‡ä¸€
                    result = future.result(timeout=timeout_seconds + 120)
                    results.append(result)
                except Exception as e:
                    console.print(f"[bold red]âŒ Error processing {example['instance_id']}: {e}[/bold red]")
                    traceback.print_exc()
                    results.append({
                        "instance_id": example["instance_id"],
                        "task_id": example.get("task_id", example["instance_id"]),
                        "query": example.get("question", ""),
                        "error": str(e),
                        "timeout": False,
                        "start_time": datetime.now().isoformat(),
                    })
                finally:
                    progress.update(task, advance=1)
    
    # ç»Ÿè®¡ç»“æœ
    completed = sum(1 for r in results if (r.get("response") or r.get("answer")) and not r.get("error"))
    timeout_count = sum(1 for r in results if r.get("timeout"))
    error_count = sum(1 for r in results if r.get("error") and not r.get("timeout"))
    
    console.print(f"\n[bold green]âœ… Completed deepsearch batch: {len(results)}/{len(examples)} tasks[/bold green]")
    console.print(f"[bold]  - Successfully completed: {completed}[/bold]")
    console.print(f"[bold]  - Timeout: {timeout_count}[/bold]")
    console.print(f"[bold]  - Errors: {error_count}[/bold]")
    console.print(f"[bold]Results directory: {output_path}[/bold]")


def main():
    parser = argparse.ArgumentParser(description="æ‰¹é‡è¿è¡Œ deepsearch æ¨ç†æ¡†æ¶")
    
    # å¤ç”¨ run_deepsearch_inference.py çš„å‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--main-model-id", 
        type=str, 
        default="us.anthropic.claude-sonnet-4-20250514-v1:0", 
        help="Main Agent çš„æ¨¡å‹ ID (é»˜è®¤: us.anthropic.claude-sonnet-4-20250514-v1:0)"
    )
    parser.add_argument(
        "--tabular-model-id", 
        type=str, 
        default="us.anthropic.claude-sonnet-4-20250514-v1:0", 
        help="Tabular Search Agent çš„æ¨¡å‹ ID (é»˜è®¤: us.anthropic.claude-sonnet-4-20250514-v1:0)"
    )
    parser.add_argument(
        "--deep-model-id", 
        type=str, 
        default="us.anthropic.claude-sonnet-4-20250514-v1:0", 
        help="Deep Search Agent çš„æ¨¡å‹ ID (é»˜è®¤: us.anthropic.claude-sonnet-4-20250514-v1:0)"
    )
    parser.add_argument("--output-dir", "-o", type=str, default="./output", help="è¾“å‡ºç›®å½• (é»˜è®¤: ./output)")
    parser.add_argument("--db-name", "-d", type=str, default="inference_db", help="æ•°æ®åº“åç§° (é»˜è®¤: inference_db)")
    parser.add_argument("--clear-db", action="store_true", default=True, help="æ¸…ç©ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨ (é»˜è®¤: True)")
    parser.add_argument("--no-clear-db", dest="clear_db", action="store_false", help="ä¸æ¸…ç©ºæ•°æ®åº“")
    parser.add_argument("--use-summary-tool", action="store_true", default=False, help="ä½¿ç”¨å¸¦æ‘˜è¦åŠŸèƒ½çš„ç½‘é¡µè®¿é—®å·¥å…· (JinaBackedVisitWebpageSummaryTool)")
    parser.add_argument("--use-out-key", action="store_true", default=False, help="ä½¿ç”¨ OUT_API_KEY å’Œ OUT_BASE_URL è€Œä¸æ˜¯ OPENAI_API_KEY å’Œ OPENAI_BASE_URL (é»˜è®¤: False)")
    
    # æ–°å¢æ‰¹é‡å¤„ç†å‚æ•°
    parser.add_argument("--input-file", "-i", type=str, 
                       default=str(BASE_DIR / "benchmark" / "gaia-text-only.jsonl"),
                       help="è¾“å…¥æ–‡ä»¶è·¯å¾„ (é»˜è®¤: benchmark/gaia-text-only.jsonl)")
    parser.add_argument("--max-workers", "-w", type=int, default=4,
                       help="æœ€å¤§å¹¶å‘æ•° (é»˜è®¤: 4)")
    parser.add_argument("--start-idx", type=int, default=0,
                       help="å¼€å§‹ç´¢å¼• (é»˜è®¤: 0)")
    parser.add_argument("--end-idx", type=int, default=None,
                       help="ç»“æŸç´¢å¼• (é»˜è®¤: None, å¤„ç†æ‰€æœ‰)")
    parser.add_argument("--tool-response-retention-budget", type=int, default=None, help="å·¥å…·å“åº”ä¿ç•™é¢„ç®— (é»˜è®¤: 5)")
    parser.add_argument(
        "--max-tool-threads", 
        type=int, 
        default=4, 
        help="æœ€å¤§å¹¶è¡Œå·¥å…·è°ƒç”¨çº¿ç¨‹æ•°ï¼Œç”¨äºæ§åˆ¶å¹¶è¡Œå·¥å…·è°ƒç”¨çš„å¹¶å‘åº¦ï¼Œé¿å… API rate-limit (é»˜è®¤: Noneï¼Œä½¿ç”¨ ThreadPoolExecutor é»˜è®¤å€¼)"
    )
    parser.add_argument("--skip-completed", action="store_true", default=True,
                       help="è·³è¿‡å·²å®Œæˆçš„ä»»åŠ¡ (é»˜è®¤: True)")
    parser.add_argument("--no-skip-completed", dest="skip_completed", action="store_false",
                       help="ä¸è·³è¿‡å·²å®Œæˆçš„ä»»åŠ¡")
    parser.add_argument("--timeout-seconds", type=int, default=3600,
                       help="ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰(é»˜è®¤: 3600, å³1å°æ—¶)")
    parser.add_argument(
        "--global-visit-limit",
        type=int,
        default=100,
        help="å…¨å±€ç½‘é¡µè®¿é—®æ¬¡æ•°é™åˆ¶ï¼Œæ‰€æœ‰ agent å…±äº«æ­¤é™åˆ¶ (é»˜è®¤: Noneï¼Œä¸é™åˆ¶)"
    )
    parser.add_argument(
        "--global-search-limit",
        type=int,
        default=100,
        help="å…¨å±€æœç´¢æ¬¡æ•°é™åˆ¶ï¼Œæ‰€æœ‰ agent å…±äº«æ­¤é™åˆ¶ (é»˜è®¤: Noneï¼Œä¸é™åˆ¶)"
    )
    parser.add_argument(
        "--main-max-step",
        type=int,
        default=40,
        help="Main Agent çš„æœ€å¤§æ­¥æ•°é™åˆ¶ (é»˜è®¤: 40)"
    )
    parser.add_argument(
        "--subagent-max-step",
        type=int,
        default=40,
        help="Sub Agent (Tabular Search Agent å’Œ Deep Search Agent) çš„æœ€å¤§æ­¥æ•°é™åˆ¶ (é»˜è®¤: 40)"
    )
    
    # Main Agent Context Summarization å‚æ•°
    parser.add_argument(
        "--main-enable-context-summarization",
        action="store_true",
        default=False,
        help="ä¸º Main Agent å¯ç”¨ context summarization åŠŸèƒ½ (é»˜è®¤: False)"
    )
    parser.add_argument(
        "--main-context-token-threshold",
        type=int,
        default=80000,
        help="Main Agent çš„ context summarization token é˜ˆå€¼ (é»˜è®¤: 80000)"
    )
    # Tabular Search Agent Context Summarization å‚æ•°
    parser.add_argument(
        "--tabular-enable-context-summarization",
        action="store_true",
        default=False,
        help="ä¸º Tabular Search Agent å¯ç”¨ context summarization åŠŸèƒ½ (é»˜è®¤: False)"
    )
    parser.add_argument(
        "--tabular-context-token-threshold",
        type=int,
        default=60000,
        help="Tabular Search Agent çš„ context summarization token é˜ˆå€¼ (é»˜è®¤: 60000)"
    )
    # Deep Search Agent Context Summarization å‚æ•°
    parser.add_argument(
        "--deep-enable-context-summarization",
        action="store_true",
        default=False,
        help="ä¸º Deep Search Agent å¯ç”¨ context summarization åŠŸèƒ½ (é»˜è®¤: False)"
    )
    parser.add_argument(
        "--deep-context-token-threshold",
        type=int,
        default=60000,
        help="Deep Search Agent çš„ context summarization token é˜ˆå€¼ (é»˜è®¤: 60000)"
    )
    # ä¾¿æ·å‚æ•°ï¼šåŒæ—¶ä¸ºæ‰€æœ‰ agent å¯ç”¨ context summarization
    parser.add_argument(
        "--enable-all-context-summarization",
        action="store_true",
        default=False,
        help="ä¸ºæ‰€æœ‰ agent (Main/Tabular/Deep) åŒæ—¶å¯ç”¨ context summarization åŠŸèƒ½ (é»˜è®¤: False)"
    )
    # Managed agent è°ƒç”¨æ¬¡æ•°é™åˆ¶å‚æ•°
    parser.add_argument(
        "--tabular-agent-limit",
        type=int,
        default=None,
        help="Tabular Search Agent çš„è°ƒç”¨æ¬¡æ•°é™åˆ¶ (é»˜è®¤: Noneï¼Œä¸é™åˆ¶)"
    )
    parser.add_argument(
        "--deep-agent-limit",
        type=int,
        default=None,
        help="Deep Search Agent çš„è°ƒç”¨æ¬¡æ•°é™åˆ¶ (é»˜è®¤: Noneï¼Œä¸é™åˆ¶)"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if not os.getenv("OPENAI_BASE_URL"):
        console.print("[yellow]âš ï¸  Warning: OPENAI_BASE_URL not set in environment[/yellow]")
    if not os.getenv("OPENAI_API_KEY"):
        console.print("[yellow]âš ï¸  Warning: OPENAI_API_KEY not set in environment[/yellow]")
    
    # å¤„ç† enable-all-context-summarization ä¾¿æ·å‚æ•°
    main_enable_ctx_sum = args.main_enable_context_summarization or args.enable_all_context_summarization
    tabular_enable_ctx_sum = args.tabular_enable_context_summarization or args.enable_all_context_summarization
    deep_enable_ctx_sum = args.deep_enable_context_summarization or args.enable_all_context_summarization
    
    # è¿è¡Œæ‰¹é‡æ¨ç†
    run_deepsearch_batch(
        input_file=args.input_file,
        main_model_id=args.main_model_id,
        tabular_model_id=args.tabular_model_id,
        deep_model_id=args.deep_model_id,
        output_dir=args.output_dir,
        db_name=args.db_name,
        clear_db=args.clear_db,
        use_summary_tool=args.use_summary_tool,
        max_workers=args.max_workers,
        start_idx=args.start_idx,
        end_idx=args.end_idx,
        skip_completed=args.skip_completed,
        timeout_seconds=args.timeout_seconds,
        tool_response_retention_budget=args.tool_response_retention_budget,
        max_tool_threads=args.max_tool_threads,
        use_out_key=args.use_out_key,
        global_visit_limit=args.global_visit_limit,
        global_search_limit=args.global_search_limit,
        main_max_steps=args.main_max_step,
        subagent_max_steps=args.subagent_max_step,
        main_enable_context_summarization=main_enable_ctx_sum,
        main_context_token_threshold=args.main_context_token_threshold,
        tabular_enable_context_summarization=tabular_enable_ctx_sum,
        tabular_context_token_threshold=args.tabular_context_token_threshold,
        deep_enable_context_summarization=deep_enable_ctx_sum,
        deep_context_token_threshold=args.deep_context_token_threshold,
        tabular_agent_limit=args.tabular_agent_limit,
        deep_agent_limit=args.deep_agent_limit
    )


if __name__ == "__main__":
    # è®¾ç½® multiprocessing å¯åŠ¨æ–¹æ³•
    # åœ¨ macOS ä¸Šä½¿ç”¨ 'spawn' (Python 3.8+ é»˜è®¤)
    # åœ¨ Linux ä¸Šå¯ä»¥ä½¿ç”¨ 'fork' ä½† 'spawn' æ›´å®‰å…¨
    # è¿™ç¡®ä¿å­è¿›ç¨‹æœ‰å¹²å‡€çš„çŠ¶æ€ï¼Œé¿å…æ½œåœ¨çš„é—®é¢˜
    try:
        multiprocessing.set_start_method('spawn', force=False)
    except RuntimeError:
        # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼Œå¿½ç•¥
        pass
    
    main()
